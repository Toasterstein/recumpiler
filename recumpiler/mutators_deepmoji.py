# pylint: disable=import-error

# TODO: pylint disables are a byproduct of us unable to install
#       deepmoji in CI
import random
from typing import List

import numpy as np

from deepmoji.global_variables import PRETRAINED_PATH, get_vocabulary
from deepmoji.model_def import deepmoji_emojis
from deepmoji.sentence_tokenizer import SentenceTokenizer


import tensorflow as tf

# from keras.backend.tensorflow_backend import set_session

# gpu compatibility for TF 2.0 with legacy keras
config = tf.compat.v1.ConfigProto()
# pylint: disable=no-member
config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU
config.log_device_placement = (
    True  # to log device placement (on which device the operation ran)
)
# (nothing gets printed in Jupyter, only if you run it standalone)
sess = tf.compat.v1.Session(config=config)
# set_session(sess)
tf.compat.v1.keras.backend.set_session(sess)

EMOJI_MAP = {
    0: "ðŸ˜‚",
    1: "ðŸ˜’",
    2: "ðŸ˜©",
    3: "ðŸ˜­",
    4: "ðŸ˜",
    5: "ðŸ˜”",
    6: "ðŸ‘Œ",
    7: "ðŸ˜Š",
    8: "â¤",
    9: "ðŸ˜",
    10: "ðŸ˜",
    11: "ðŸŽ¶",
    12: "ðŸ˜³",
    13: "ðŸ’¯",
    14: "ðŸ˜´",
    15: "ðŸ˜Œ",
    16: "â˜º",
    17: "ðŸ™Œ",
    18: "ðŸ’•",
    19: "ðŸ˜‘",
    20: "ðŸ˜…",
    21: "ðŸ™",
    22: "ðŸ˜•",
    23: "ðŸ˜˜",
    24: "â™¥",
    25: "ðŸ˜",
    26: "ðŸ’",
    27: "ðŸ˜ž",
    28: "ðŸ™ˆ",
    29: "ðŸ˜«",
    30: "âœŒ",
    31: "ðŸ˜Ž",
    32: "ðŸ˜¡",
    33: "ðŸ‘",
    34: "ðŸ˜¢",
    35: "ðŸ˜ª",
    36: "ðŸ˜‹",
    37: "ðŸ˜¤",
    38: "âœ‹",
    39: "ðŸ˜·",
    40: "ðŸ‘",
    41: "ðŸ‘€",
    42: "ðŸ”«",
    43: "ðŸ˜£",
    44: "ðŸ˜ˆ",
    45: "ðŸ˜“",
    46: "ðŸ’”",
    47: "â™¡",
    48: "ðŸŽ§",
    49: "ðŸ™Š",
    50: "ðŸ˜‰",
    51: "ðŸ’€",
    52: "ðŸ˜–",
    53: "ðŸ˜„",
    54: "ðŸ˜œ",
    55: "ðŸ˜ ",
    56: "ðŸ™…",
    57: "ðŸ’ª",
    58: "ðŸ‘Š",
    59: "ðŸ’œ",
    60: "ðŸ’–",
    61: "ðŸ’™",
    62: "ðŸ˜¬",
    63: "âœ¨",
}


def top_elements(array, k):
    ind = np.argpartition(array, -k)[-k:]
    return ind[np.argsort(array[ind])][::-1]


def elements_past_min(array, min_dist: float):
    return np.argwhere(array > min_dist).flatten()


def get_top_n_emojis(
    st, deepmoji_model, sentence: str, most_n: int = 5, min_dist: float = None
) -> List[str]:
    tokenized, _, _ = st.tokenize_sentences([sentence])
    prob = deepmoji_model.predict(tokenized)
    for i, t_prob in enumerate(prob):
        if min_dist is not None:
            ids = list(
                i
                for i in top_elements(t_prob, most_n)
                if i in elements_past_min(t_prob, min_dist)
            )
        else:
            ids = list(top_elements(t_prob, most_n))
        return list([EMOJI_MAP[emoji_index] for emoji_index in ids])


sentence_tokenizer = SentenceTokenizer(get_vocabulary(), 30)
deepmoji_model = deepmoji_emojis(
    maxlen=30,
    weight_path=PRETRAINED_PATH,
)


deepmoji_model.summary()


def sentiment_query(word: str, most_n: int = 5, min_dist: float = None):
    return get_top_n_emojis(
        sentence_tokenizer, deepmoji_model, word, most_n=most_n, min_dist=min_dist
    )


sentiment_query("I lost my dog oh no")


import enum


class deepmoji_lookup_accuracy(enum.Enum):
    low = 0.01
    med = 0.04
    high = 0.07


def get_sentiment_emoji(sentance):
    emojis = sentiment_query(
        str(sentance), most_n=3, min_dist=deepmoji_lookup_accuracy.high.value
    )
    if emojis:
        # TODO: maybe smarter grab
        return random.choice(emojis)
    return None
